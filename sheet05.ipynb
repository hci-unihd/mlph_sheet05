{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 QDA\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.load('data/data1d.npy')\n",
    "labels = np.load('data/labels1d.npy')\n",
    "\n",
    "# TODO: group the points into two arrays pts0, pts1 according to the labels\n",
    "\n",
    "# TODO: compute the mean and standard deviations for each class (and print them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# TODO: evaluate the Gaussian class densities in a range from -5 to 5\n",
    "\n",
    "# TODO: evaulate the posterior p(y=1|x)\n",
    "\n",
    "# TODO: plot the class densities and the posterior p(y=1|x). (Don't forget title, axis labels, legend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Trees and Random Forests\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "pts = np.load('data/data1d.npy')\n",
    "labels = np.load('data/labels1d.npy')\n",
    "\n",
    "# TODO: Sort the points to easily split them\n",
    "\n",
    "# TODO: Implement or find implementation for Gini impurity, entropy and misclassifcation rate\n",
    "\n",
    "# TODO: Iterate over the possible splits, evaulating and saving the three criteria for each one\n",
    "    \n",
    "# TODO: Compute the split that each criterion favours and visualize them \n",
    "#       (e.g. with a histogram for each class and vertical lines to show the splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dijet data\n",
    "features = np.load('data/dijet_features_normalized.npy')\n",
    "labels = np.load('data/dijet_labels.npy')\n",
    "\n",
    "# TODO: define train, val and test splits as specified (make sure to shuffle the data before splitting it!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: train a random forest classifier for each combination of hyperparameters as specified on the sheet\n",
    "#       and evaluate the performances on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for your preferred configuration, evaluate the performance of the best configuration on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Beta Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.load('data/data1d.npy')\n",
    "labels = np.load('data/labels1d.npy')\n",
    "\n",
    "# split the data into the classes\n",
    "pts1 = pts[labels==0]\n",
    "pts2 = pts[labels==1]\n",
    "\n",
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(15, 1))\n",
    "plt.scatter(pts1, np.ones_like(pts1), label='pts1', marker='|', alpha=0.3)\n",
    "plt.scatter(pts2, np.zeros_like(pts2), label='pts2', marker='|', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.ylim(-0.2, 1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma, gammaln\n",
    "\n",
    "def beta_pdf(x, a, b):\n",
    "    \"\"\"Probability density function for the Beta distribution with parameters a and b. Works verctorized over all inputs\"\"\"\n",
    "#     return (gamma(a+b) * x**(a-1) * (1-x)**(b-1)) / gamma(a) / gamma(b)  # breaks down for larger a, b\n",
    "    return np.exp(gammaln(a+b) - gammaln(a) - gammaln(b) + np.log(x)*(a-1) + np.log(1-x)*(b-1))  # works for larger a, b\n",
    "\n",
    "eps = 1e-6\n",
    "x = np.linspace(eps, 1-eps, 1000, endpoint=True)\n",
    "for a, b in ((0.1, 0.1), (0.1, 1), (1, 1), (2, 2), (10, 10), (5, 15)):\n",
    "    plt.plot(x, beta_pdf(x, a, b), label=f'{a=}, {b=}')\n",
    "plt.legend()\n",
    "plt.ylim(0, 5)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Beta distribution for different parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_points_within_distance(x, pts, r):\n",
    "    \"\"\"\n",
    "    Count number of points among pts within a distance r of query points x (in 1D).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Query points of shape (M).\n",
    "    pts : np.ndarray\n",
    "        Points to be searched, shape (N).\n",
    "    r : float\n",
    "        radius.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of counts of shape (M)\n",
    "        \n",
    "    \"\"\"\n",
    "    # TODO: sort the points\n",
    "    \n",
    "    # TODO: use np.searchsorted on the interval boundaries \n",
    "    #       to find number of points inside each interval (don't use loops!)\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# use a flat prior\n",
    "prior_a, prior_b = 1, 1  \n",
    "\n",
    "# define value range\n",
    "vmin, vmax = -5, 5\n",
    "\n",
    "# set the radius\n",
    "r = .3\n",
    "\n",
    "# TODO: sample x and mu as described in the exercise\n",
    "\n",
    "# TODO: use count_points_within_distance to calculate the counts\n",
    "\n",
    "# TODO (optional): plot the counts vs x\n",
    "\n",
    "# TODO: evaluate the posterior to get an image (use broadcasting, no loops needed!)\n",
    "\n",
    "# TODO: plot the posterior as an image, specify the correct origin and extent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlph]",
   "language": "python",
   "name": "conda-env-mlph-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
